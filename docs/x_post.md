# FlightMind: An LLM That Trains Itself Through Flight

**Post for X (long-form / thread)**

---

## HOOK POST (with closed_loop_architecture.png attached)

I'm building an LLM from scratch that trains on data generated by the autonomous flight system it powers.

The system improves itself: fly missions, log data, train the model, deploy it back, fly better missions. Repeat.

It's called FlightMind, and it's the language brain for AIDA -- an autonomous Cessna 172 that flies cross-country with natural language pilot interaction.

Here's how it works. (thread)

---

## POST 2 — The Problem (with architecture_scaling.png attached)

AIDA currently uses Llama 8B (quantized) for command parsing. It works, but:

- 5 GB VRAM for a model that mostly parses "turn heading 270"
- ~500ms latency per inference -- slow for real-time flight
- Zero aviation domain knowledge out of the box
- Licensed under Meta's terms

So we're replacing it with a purpose-built model. Not fine-tuning Llama -- building from scratch.

One integer, `depth`, controls the entire architecture. d8 = 50M params. d24 = 956M. d32 = 2.2B. Same code, same ratios, just scale the number.

---

## POST 3 — The Closed Loop (with data_composition.png attached)

Here's where it gets interesting.

AIDA is a training platform. Every autonomous flight generates:
- 148,000+ intent observations (command/action pairs with Bayesian validation)
- 40 cross-country flight recordings (50Hz state vectors, 15 flight phases)
- Full telemetry: altitude, airspeed, heading, control inputs, phase transitions

We built converters that transform this raw flight data into 303,173 instruction-response pairs. The model learns to parse pilot commands AND narrate flight status in a single inference.

Pretraining corpus: 192M tokens from NTSB reports, METARs, FAA handbooks, regulations, aircraft performance data.

Fine-tuning data: 303K pairs generated entirely by AIDA.

The model learns aviation from public data. It learns AIDA's specific language from AIDA itself.

---

## POST 4 — Training Results (with training_loss.png attached)

The d8 proof-of-concept (50M params) just finished training on a single RTX 4060.

5,000 steps. 10.3 hours. 1.31 billion tokens. Results:
- Loss: 10.45 --> 1.60 (random --> coherent aviation text)
- Best val loss: 1.95 at step 3,500 (perplexity 7.0)
- Evaluation perplexity: 8.12 on held-out aviation data
- Generation: 71 tokens/sec on the same GPU
- Throughput: 35K tokens/sec during training
- GPU: 64C, 99% utilization, zero crashes

For reference, GPT-2 (124M params) achieves perplexity ~29 on general web text. Our 50M model hits 8.12 on aviation text -- less than half the params, a quarter the perplexity. Domain specialization works.

---

## POST 5 — What Comes Next (with training_dashboard.png attached)

d8 proof-of-concept: done. The plan from here:

1. LoRA fine-tune d8 on the 303K AIDA instruction pairs -- free (local GPU)
2. Pretrain d24 (956M) on a cloud A100 -- ~$50-100
3. Fine-tune d24, deploy back to AIDA as a drop-in replacement for Llama 8B

The d24 model at inference needs ~2.5 GB VRAM. Llama 8B Q4 needs ~5 GB. Same RTX 4060, half the memory, 4x faster inference, aviation-native understanding.

Every line of code is written from scratch and documented -- from the BPE tokenizer to the transformer to the LoRA fine-tuner. No frameworks beyond PyTorch.

---

## POST 6 — Links

All open source. Every design decision documented:

GitHub: https://github.com/kushkoirala/FlightMind
AIDA: https://github.com/kushkoirala/AIDA

Built with: PyTorch, Flash Attention, custom BPE tokenizer
Architecture: RoPE + SwiGLU + RMSNorm + weight tying (the modern LLM stack)
Inspired by: @kaborke's nanochat approach to depth parameterization

If you're interested in LLMs from scratch, autonomous flight, or the intersection of both -- follow along. The d8 is trained and evaluated. d24 is next.

---

## SUGGESTED IMAGES PER POST

| Post | Attach | File |
|------|--------|------|
| 1 (Hook) | Closed-loop diagram | `docs/figures/closed_loop_architecture.png` |
| 2 (Problem) | Scaling chart | `docs/figures/architecture_scaling.png` |
| 3 (Data) | Data composition | `docs/figures/data_composition.png` |
| 4 (Results) | Loss curve | `docs/figures/training_loss.png` |
| 5 (Next) | Full dashboard | `docs/figures/training_dashboard.png` |
| 6 (Links) | None or repo screenshot | -- |

## ALT: SINGLE POST VERSION (if not doing a thread)

I'm building an LLM from scratch to power an autonomous Cessna 172.

The twist: the flight system (AIDA) generates the training data that trains the model that powers AIDA. A closed loop -- each iteration, better flights produce better data produce a better model.

50M param proof-of-concept just finished training on a single RTX 4060. 5,000 steps, 10.3 hours, 1.31B tokens. Perplexity: 8.12 -- GPT-2 (124M) gets ~29 on general text. Half the params, quarter the perplexity. Domain specialization works.

Next: LoRA fine-tune on 303K instruction pairs from real autonomous flights, then scale to 956M params on cloud GPU and deploy back to AIDA.

Every line from scratch. Fully open source.

https://github.com/kushkoirala/FlightMind
